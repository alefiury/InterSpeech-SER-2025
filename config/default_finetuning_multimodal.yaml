title: SER-Dynamic_Audio_Text-FineTuning-(Loss-${loss.name})-(BS-${data.use_balanced_sampling})-(BS-Scheduler-${data.use_balanced_sampling_scheduler})-(TextAug-${data.use_text_augmentation})-(${model.audio_model_name})-(FreezeBackbone-${model.freeze_audio_backbone})-(LayerStrategy-${model.audio_layer_weight_strategy})-(Pooling-${model.audio_pooling_strategy})-(${model.text_model_name})-(FreezeBackbone-${model.freeze_text_backbone})-(LayerStrategy-${model.text_layer_weight_strategy})-(Pooling-${model.text_pooling_strategy})-(epochs-${trainer.max_epochs})-(bs-${train.batch_size})-(LR-${optimizer.params.learning_rate})

wandb_entity: alefiury

loss:
    name: "focal"
    gamma: 2.0
    alpha: 0.5
    use_weighted_loss: false # Uses "prior" weights as in https://www.isca-archive.org/odyssey_2024/chen24_odyssey.pdf

datasets:
    train:
        - name: Train
          metadata_path: "/hadatasets/alef.ferreira/SER/Interspeech/InterSpeech-SER-2025/Dataset/transcribed_canary_train_set.csv"
          base_dir: "/hadatasets/alef.ferreira/SER/Interspeech/Audios"
          filename_column: "FileName"
          transcript_column: "Transcript"
          target_column: "EmoClass"

    val:
        - name: Validation
          metadata_path: "/hadatasets/alef.ferreira/SER/Interspeech/InterSpeech-SER-2025/Dataset/transcribed_canary_validation_set.csv"
          base_dir: "/hadatasets/alef.ferreira/SER/Interspeech/Audios"
          filename_column: "FileName"
          transcript_column: "Transcript"
          target_column: "EmoClass"

data:
    num_classes: 8

    target_sr: 16000

    use_balanced_sampling: true # If true, the dataset will be balanced based on the inverse frequency of the classes
    use_balanced_sampling_scheduler: true # If true, the dataset will be balanced based on the inverse frequency of the classes, but the weights will be updated during training

    mixup_alpha: 0.0 # 0.0 to disable mixup, if you want to use mixup, set this value to 0.5 (recommended)

    use_rand_truncation: true # If true, the audio will be randomly truncated between min_duration and the original duration
    min_duration: 2.0 # min duration (in seconds), only used if use_rand_truncation is True

    use_background_noise: true # If true, background noise will be added to the audio (Music and environmental noise)
    background_noise_dir: "/hadatasets/alef.ferreira/SER/Interspeech/InterSpeech-SER-2025/augmentation_data/musan"
    background_noise_min_snr_in_db: 3.0
    background_noise_max_snr_in_db: 15.0
    background_noise_p: 0.5

    use_rir: true # If true, RIRs (reverberation) will be added to the audio
    rir_dir: "/hadatasets/alef.ferreira/SER/Interspeech/InterSpeech-SER-2025/augmentation_data/RIRS_NOISES"
    rir_p: 0.5

    # Text augmentation
    use_text_augmentation: false # If true, text augmentation will be used (random word deletion)
    text_augmentation_p: 0.5

    # label2id must represent the names of the target in the metadata file
    label2id: {
        "A": 0,
        "C": 1,
        "D": 2,
        "F": 3,
        "H": 4,
        "N": 5,
        "S": 6,
        "U": 7
    }

train:
    batch_size: 16
    shuffle: True
    num_workers: 12

model:
    model_type: "dynamic_audio_text"

    # Audio config
    audio_model_name: "microsoft/wavlm-large"
    # model_name: "facebook/wav2vec2-xls-r-300m"
    # model_name: "facebook/hubert-large-ls960-ft"
    # model_name: "openai/whisper-large"
    freeze_audio_backbone: true
    audio_layer_weight_strategy: "per_layer"
    # audio_layer_weight_strategy: "weighted_sum"
    audio_num_feature_layers: 25
    specific_audio_layer_idx: -1
    audio_pooling_strategy: "mean"

    # Text config
    text_model_name: "intfloat/e5-large-v2"
    freeze_text_backbone: true
    text_layer_weight_strategy: "per_layer"
    # text_layer_weight_strategy: "weighted_sum"
    text_num_feature_layers: 25
    specific_text_layer_idx: -1
    text_pooling_strategy: "mean"

    # MLP config
    mlp_input_dim: 2048 # Must be adapted to the model, when using attention pooling, this value should be the double of the model hidden size
    mlp_hidden_dim: ${model.mlp_input_dim} # Must be adapted to the model, should be the same as mlp_input_dim
    mlp_num_layers: 1
    mlp_output_size: ${data.num_classes}
    mlp_dropout: 0.2
    mlp_activation_func: "relu"

    # Projection config
    audio_feat_dim: 1024
    text_feat_dim: 1024
    audio_proj_dropout: 0.2
    text_proj_dropout: 0.2

optimizer:
    name: "adamw"
    params:
        min_learning_rate: 1e-5 # Same used in https://ecs.utdallas.edu/research/researchlabs/msp-lab/publications/Goncalves_2024.pdf
        learning_rate: 5e-5 # Same used in https://ecs.utdallas.edu/research/researchlabs/msp-lab/publications/Goncalves_2024.pdf
        eps: 1e-8
        weight_decay: 1e-6
        betas: [0.9, 0.98]

scheduler:
    name: "CosineWarmupLR"
    params:
        warmup_lr: 500

tags:
    - ${train.batch_size}-BS
    - LR-${optimizer.params.learning_rate}
    - WD-${optimizer.params.weight_decay}
    - BS-${data.use_balanced_sampling}
    - Mixup-${data.mixup_alpha}
    - RTrunc-${data.use_rand_truncation}
    - BNoise-${data.use_background_noise}
    - RIR-${data.use_rir}
    - ${model.mlp_input_dim}-AH
    - ${model.mlp_hidden_dim}-HL
    - ${model.mlp_num_layers}-IS

trainer:
    accelerator: "gpu"
    max_epochs: 10
    num_sanity_val_steps: 2
    overfit_batches: 0.0
    log_every_n_steps: 10
    gradient_clip_val: 10.0
    gradient_clip_algorithm: "norm"
    val_check_interval: 1.0
    accumulate_grad_batches: 1
    reload_dataloaders_every_n_epochs: 1 # This should be set to 1 if "data.use_balanced_sampling_scheduler" is True

model_checkpoint:
    mode: "max"
    save_last: true
    save_weights_only: true
    monitor: "val/f1-score"
    dirpath: "../checkpoints/ser-2025"
    filename: "{epoch:02d}-{step:02d}-{val/f1-score:.4f}"